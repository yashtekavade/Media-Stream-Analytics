# Media Stream Analytics

A real-time media streaming analytics platform built on AWS services for processing and analyzing viewership data.

## ğŸ—ï¸ Architecture Overview

This project implements a complete data pipeline for media streaming analytics using:

- **Amazon Kinesis** - Real-time data streaming
- **AWS Glue** - ETL processing and data transformation
- **AWS Lambda** - Serverless compute for triggers
- **Apache Airflow** - Workflow orchestration
- **Snowflake** - Data warehousing
- **Amazon EMR Spark** - Distributed data processing

## ğŸ“ Project Structure

```
Media-Stream-Analytics/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ docs/                    # Documentation
â”‚   â””â”€â”€ Version_1_AWS_Project_2.pdf
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ airflow/            # Airflow DAGs
â”‚   â”‚   â””â”€â”€ dags/
â”‚   â”‚       â””â”€â”€ media_analytics_dag.py
â”‚   â”œâ”€â”€ kinesis/            # Kinesis streaming components
â”‚   â”‚   â”œâ”€â”€ data_generator.py     # Generates sample data
â”‚   â”‚   â””â”€â”€ stream_processor.py   # Processes Kinesis streams
â”‚   â”œâ”€â”€ glue/               # AWS Glue ETL jobs
â”‚   â”‚   â””â”€â”€ etl_job.py
â”‚   â”œâ”€â”€ lambda/             # Lambda functions
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ trigger_airflow_dag.py
â”‚   â””â”€â”€ data_generation/    # Data generation utilities
â”‚       â””â”€â”€ generate_media_data.py
â””â”€â”€ infrastructure/         # Infrastructure setup
    â””â”€â”€ snowflake_setup.txt
```

## ğŸš€ Features

- **Real-time Data Ingestion**: Continuous streaming of viewership data via Kinesis
- **ETL Processing**: Automated data transformation using AWS Glue
- **Workflow Orchestration**: Managed data pipelines with Apache Airflow
- **Scalable Processing**: Distributed computing with EMR Spark
- **Data Warehousing**: Optimized storage and querying with Snowflake
- **Serverless Triggers**: Event-driven processing with Lambda functions

## ğŸ“Š Data Flow

1. **Data Generation** â†’ Media viewership data is generated and streamed
2. **Kinesis Ingestion** â†’ Real-time data streaming to Kinesis Data Streams
3. **Lambda Trigger** â†’ Serverless functions trigger downstream processing
4. **Glue ETL** â†’ Data transformation and cleaning
5. **EMR Spark** â†’ Large-scale data processing
6. **Snowflake** â†’ Data warehousing and analytics
7. **Airflow Orchestration** â†’ Workflow management and scheduling

## ğŸ› ï¸ Setup Instructions

### Prerequisites

- AWS Account with appropriate permissions
- Python 3.8+
- Apache Airflow
- Snowflake account

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yashtekavade/Media-Stream-Analytics.git
   cd Media-Stream-Analytics
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure AWS credentials**
   ```bash
   aws configure
   ```

4. **Set up Kinesis Data Stream**
   - Create a Kinesis Data Stream named `viewership-stream`
   - Configure appropriate shard count based on expected throughput

5. **Deploy Glue Job**
   - Upload the Glue ETL script to S3
   - Create AWS Glue job with appropriate IAM roles

6. **Configure Airflow**
   - Deploy DAGs to your Airflow environment
   - Set up AWS connections in Airflow

7. **Set up Snowflake**
   - Follow instructions in `infrastructure/snowflake_setup.txt`

## ğŸ”§ Usage

### Running Data Generation
```bash
python src/data_generation/generate_media_data.py
```

### Streaming Data to Kinesis
```bash
python src/kinesis/data_generator.py
```

### Triggering Airflow DAG
Deploy the Lambda function and configure appropriate triggers, or manually trigger via Airflow UI.

## ğŸ“‹ Components Description

### Kinesis Components
- **data_generator.py**: Streams viewership data to Kinesis
- **stream_processor.py**: Processes data from Kinesis using EMR Spark

### Airflow DAGs
- **media_analytics_dag.py**: Orchestrates the complete ETL pipeline

### AWS Glue
- **etl_job.py**: Performs data transformation and loading

### Lambda Functions
- **trigger_airflow_dag.py**: Triggers Airflow workflows based on events

## ğŸ” Monitoring & Logging

- Monitor Kinesis streams via CloudWatch
- Track Glue job execution in AWS Glue console
- Monitor Airflow DAG runs in Airflow UI
- View Lambda function logs in CloudWatch Logs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ“ Contact

For questions or support, please reach out to the project maintainer.

---

**Note**: Make sure to configure all AWS services with appropriate IAM roles and security groups before running the pipeline.
